{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "59mxSrnSrpMx",
        "outputId": "90886061-dc75-44ce-855f-321cecb38bb2"
      },
      "outputs": [],
      "source": [
        "!unzip torch-it-up.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcCfPdFXW1gT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset, random_split\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IezcTbojW4nH"
      },
      "outputs": [],
      "source": [
        "# Check GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEb4oKVKW6vB"
      },
      "outputs": [],
      "source": [
        "# Define paths\n",
        "DATASET_PATH = \"./dataset\"\n",
        "TRAIN_CSV = os.path.join(DATASET_PATH, \"train.csv\")\n",
        "TEST_CSV = os.path.join(DATASET_PATH, \"test.csv\")\n",
        "IMAGE_FOLDER = os.path.join(DATASET_PATH, \"Dataset_Image/Dataset_Image\")\n",
        "\n",
        "# Load CSV\n",
        "train_df = pd.read_csv(TRAIN_CSV)\n",
        "test_df = pd.read_csv(TEST_CSV)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMW8GEDWW-jt"
      },
      "outputs": [],
      "source": [
        "# Remap labels to 0-based index\n",
        "unique_labels = sorted(train_df['label'].unique())\n",
        "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "train_df['label'] = train_df['label'].map(label_mapping)\n",
        "num_classes = len(unique_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5WgHv4qXBT4"
      },
      "outputs": [],
      "source": [
        "# Data Augmentation for Training\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1)),  # Random rotations and shifts\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Transform for Test (No Augmentation)\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4x9v5T02XF_0"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class SymbolDataset(Dataset):\n",
        "    def __init__(self, dataframe, img_dir, transform=None, train=True):\n",
        "        self.dataframe = dataframe\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.train = train\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.dataframe.iloc[idx]['image_path'])\n",
        "        image = Image.open(img_path).convert(\"L\")  # Convert grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.train:\n",
        "            label = int(self.dataframe.iloc[idx]['label'])\n",
        "            return image, label\n",
        "        else:\n",
        "            example_id = self.dataframe.iloc[idx]['example_id']\n",
        "            return image, example_id\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDiyLN9sXM9B"
      },
      "outputs": [],
      "source": [
        "# Train-Test Split (98% Train, 2% Validation)\n",
        "train_size = int(0.98 * len(train_df))\n",
        "val_size = len(train_df) - train_size\n",
        "\n",
        "train_dataset, val_dataset = random_split(\n",
        "    SymbolDataset(train_df, IMAGE_FOLDER, transform=train_transform, train=True),\n",
        "    [train_size, val_size]\n",
        ")\n",
        "\n",
        "# Dataloaders (Optimized for Speed)\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(SymbolDataset(test_df, IMAGE_FOLDER, transform=test_transform, train=False),\n",
        "                         batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uun-qY2-XQQV"
      },
      "outputs": [],
      "source": [
        "# Define Model (ResNet18 with Modified Input Layer)\n",
        "class SymbolClassifier(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SymbolClassifier, self).__init__()\n",
        "        self.model = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1, bias=False)  # Change to 1-channel input\n",
        "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Initialize Model, Loss, and Optimizer\n",
        "model = SymbolClassifier(num_classes).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2, verbose=True)\n",
        "\n",
        "# Mixed Precision Training for Speedup\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "# Training Loop\n",
        "epochs = 45\n",
        "best_acc = 0.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "Cy02lR-NrhiW",
        "outputId": "274ead94-1d03-4ca2-a8af-724241ba6c0d"
      },
      "outputs": [],
      "source": [
        "for epoch in range(epochs):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():  # Mixed precision\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_acc = 100 * correct / total\n",
        "    print(f\" Loss: {running_loss/len(train_loader):.4f}, Accuracy: {train_acc:.2f}%\")\n",
        "\n",
        "    # Validation Step\n",
        "    model.eval()\n",
        "    correct, total = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            total += labels.size(0)\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    # Early Stopping & LR Reduction\n",
        "    scheduler.step(val_acc)\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        torch.save(model.state_dict(), \"./best_model.pth\")  # Save best model\n",
        "        print(\"Model improved, saved!\")\n",
        "\n",
        "print(\"Training complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeUA-ABxXVY8"
      },
      "outputs": [],
      "source": [
        "# Load Best Model for Submission\n",
        "model.load_state_dict(torch.load(\"./best_model.pth\"))\n",
        "model.eval()\n",
        "\n",
        "# Generate Predictions\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images, example_ids in tqdm(test_loader, desc=\"Generating Predictions\"):\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        for eid, pred in zip(example_ids, predicted.cpu().numpy()):\n",
        "            predictions.append((eid, unique_labels[pred]))  # Convert back to original label\n",
        "\n",
        "# Create Submission File\n",
        "submission_df = pd.DataFrame(predictions, columns=[\"example_id\", \"label\"])\n",
        "submission_df.to_csv(\"./submission.csv\", index=False)\n",
        "print(\"Submission file saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjrmf6I61B2c"
      },
      "outputs": [],
      "source": [
        "!sed -E 's/tensor\\(([0-9]+)\\)/\\1/' submission.csv > cleaned_file.csv\n",
        "!mv submission.csv unfor_sub.csv\n",
        "!mv cleaned_file.csv submission.csv"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
